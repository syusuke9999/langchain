{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20c4e38",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory\n",
    "\n",
    "`ConversationBufferWindowMemory` は、会話のやりとりのリストを時系列で保持します。これは、バッファが大きくなりすぎないように、最新の対話に関するスライディングウィンドウを保持するのに便利です。\n",
    "\n",
    "まず、このタイプのメモリーの基本的な関数を調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1196da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory( k=1)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"ouput\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"ouput\": \"not much\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c034a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5cce1d",
   "metadata": {},
   "source": [
    "また、履歴をメッセージのリストとして取得することもできます（このモデルはチャットモデルで使用する場合に便利です）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory( k=1, return_messages=True)\n",
    "memory.save_context({\"input\": \"やぁ\"}, {\"ouput\": \"どうしたの\"})\n",
    "memory.save_context({\"input\": \"なにもない\"}, {\"ouput\": \"なにも\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb47191",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95af04c",
   "metadata": {},
   "source": [
    "## チェーンで使用する\n",
    "プロンプトが表示されるように `verbose=True` を設定して、サンプルを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9da4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    # We set a low k=2, to only keep the last 2 interactions in memory\n",
    "    memory=ConversationBufferWindowMemory(k=2), \n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"こんにちは、どうしましたか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f73431",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"彼らの抱える問題とは？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb499e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"うまくいっているのでしょうか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d209cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice here that the first interaction does not appear.\n",
    "conversation_with_summary.predict(input=\"その解決策とは？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09a239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

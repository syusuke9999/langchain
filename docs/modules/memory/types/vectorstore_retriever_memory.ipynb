{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4be5f3",
   "metadata": {},
   "source": [
    "# VectorStoreを利用したメモリ\n",
    "\n",
    "`VectorStoreRetrieverMemory`は、メモリをVectorDBに格納し、呼び出されるたびに上位K個の最も「重要」なドキュメントを問い合わせます。\n",
    "\n",
    "これは、他のほとんどのMemoryクラスと異なり、対話の順序を明示的に追跡しない点が異なります。\n",
    "\n",
    "この場合 \"docs \" は以前の会話のスニペットです。これはAIが会話の中で以前に聞いた、関連のある情報の断片を参照するのに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3384db",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:54:37.841707200Z",
     "start_time": "2023-05-15T02:54:34.874643300Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7abdf",
   "metadata": {},
   "source": [
    "### VectorStoreを初期化する\n",
    "\n",
    "選択したストアによって、このステップの内容は異なる場合があります。詳細については、関連するVectorStoreのドキュメントを参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef56f65",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:54:38.242617100Z",
     "start_time": "2023-05-15T02:54:37.844708400Z"
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Dimensions of the OpenAIEmbeddings\n",
    "# OpenAIEmbeddingsのディメンション\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "embedding_fn = OpenAIEmbeddings().embed_query\n",
    "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4bdf92",
   "metadata": {},
   "source": [
    "### VectorStoreRetrieverMemory を作成する\n",
    "\n",
    "メモリオブジェクトは、任意の VectorStoreRetriever からインスタンス化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00d4938",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:55:00.042939900Z",
     "start_time": "2023-05-15T02:54:58.567928500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 実際の使用では、`k`をより高い値に設定することになりますが、ここではk=1に設定して\n",
    "# ベクトルルックアップが意味的に関連する情報を返すことを示します。\n",
    "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# メモリオブジェクトは、エージェントに追加すると、会話や使用したツールから適切な情報を保存することができます。\n",
    "memory.save_context({\"input\": \"好きな食べ物はピザです\"}, {\"output\": \"それはよかった\"})\n",
    "memory.save_context({\"input\": \"好きなスポーツはサッカーです。\"}, {\"output\": \"...\"})\n",
    "memory.save_context({\"input\": \"セルティックスはしない\"}, {\"output\": \"ok\"}) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe28a28",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:55:01.828457600Z",
     "start_time": "2023-05-15T02:55:01.355167100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 好きなスポーツはサッカーです。\n",
      "output: ...\n"
     ]
    }
   ],
   "source": [
    "# 最初に返された結果は、税務相談に関連する記憶であり、言語モデルは、\n",
    "# 他のドキュメントよりも1099に意味的に関連していると判断しています（どちらも数字が含まれているにもかかわらず）。\n",
    "print(memory.load_memory_variables({\"prompt\": \"what sport should i watch?\"})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2569f",
   "metadata": {},
   "source": [
    "## チェーンでの使用\n",
    "例を見ていきましょう。`verbose=True` を設定してプロンプトを表示できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd68c10",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:55:06.516972600Z",
     "start_time": "2023-05-15T02:55:06.504933Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0) # Can be any valid LLM\n",
    "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Relevant pieces of previous conversation:\n",
    "{history}\n",
    "\n",
    "(You do not need to use these pieces of information if not relevant)\n",
    "\n",
    "Current conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=PROMPT,\n",
    "    # テストのため、非常に低いmax_token_limitを設定しました。\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: 好きな食べ物はピザです\n",
      "output: それはよかった\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: こんにちは、私の名前はペリーです、どうしましたか？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' こんにちは、ペリーさん。私の名前はAIです。元気です。あなたは何をしていますか？'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"こんにちは、私の名前はペリーです、どうしましたか？\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T02:55:10.882934400Z",
     "start_time": "2023-05-15T02:55:07.723243300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86207a61",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:55:45.306582700Z",
     "start_time": "2023-05-15T02:55:41.126695500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: 好きなスポーツはサッカーです。\n",
      "output: ...\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: 私の好きなスポーツは何ですか？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' 私にはわかりませんが、あなたが言ったように、あなたの好きなスポーツはサッカーですね。'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ここでは、バスケットボール関連のコンテンツを浮上させる\n",
    "conversation_with_summary.predict(input=\"私の好きなスポーツは何ですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c669db1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:57:44.971348600Z",
     "start_time": "2023-05-15T02:57:34.568643300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: 私の好きな食べ物は？\n",
      "response:  私にはそれを知る能力がありませんが、あなたの好きな食べ物は何ですか？\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: 私の好きな食べ物は？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' 私はあなたの好きな食べ物を知りませんが、あなたが好きな食べ物を教えてくれると嬉しいです！あなたの好きな食べ物は何ですか？'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 言語モデルがステートレス（状態を持たない）であっても、関連するメモリがフェッチされるため、時間について「推論」することができます。\n",
    "# メモリやデータのタイムスタンプは、エージェントに時間的な関連性を判断させるために、一般的に有用である。\n",
    "conversation_with_summary.predict(input=\"私の好きな食べ物は？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c09a239",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-15T02:59:15.060498500Z",
     "start_time": "2023-05-15T02:59:11.960745500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Relevant pieces of previous conversation:\n",
      "input: こんにちは、私の名前はペリーです、どうしましたか？\n",
      "response:  こんにちは、ペリーさん。私の名前はAIです。元気です。あなたは何をしていますか？\n",
      "\n",
      "(You do not need to use these pieces of information if not relevant)\n",
      "\n",
      "Current conversation:\n",
      "Human: 私の名前は何ですか？\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' あなたの名前はペリーさんですね。あなたは何をしていますか？'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会話からのメモリは自動的に保存されます。\n",
    "# このクエリが上記のイントロダクションチャットと最もよく一致するため、\n",
    "# エージェントはユーザーの名前を「覚えている」ことができます。\n",
    "conversation_with_summary.predict(input=\"私の名前は何ですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27c7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
